{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# past_data = pd.read_csv('2014-2019.csv')\n",
    "# past_data = past_data[:1459]\n",
    "# tmp_data = pd.read_csv('2018-2020.csv')\n",
    "# past_data = past_data.append(tmp_data)\n",
    "# current_data = pd.read_csv('2021year.csv')\n",
    "# data = past_data.append(current_data)\n",
    "# data = data.reset_index()\n",
    "# data['備轉'] = data['備轉容量(萬瓩)']*10\n",
    "# # tmp = []\n",
    "# # for i in data.index:\n",
    "# #     tmp.append(datetime.datetime.strptime(str(data.loc[i, '日期']), '/%Y/%m/%d'))\n",
    "# # data['date'] = [i.weekday() for i in tmp]\n",
    "# def normalize(train):\n",
    "#     train_norm = train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "#     return train_norm\n",
    "# data[['backup']] = normalize(data[['備轉']])\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2492, 7, 1)\n",
      "(2492, 1)\n",
      "(136, 7, 1)\n",
      "(136, 1)\n"
     ]
    }
   ],
   "source": [
    " def create_data(past = 7, future = 7):\n",
    "    # model = build()\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for i in range(past+future, len(data)+1):\n",
    "        t = data.iloc[i-past-future:i-future][['備轉']]\n",
    "        y = data['備轉'].iloc[i-future:i]\n",
    "        if i < 2500:\n",
    "            x_train.append(t)\n",
    "            y_train.append(y)\n",
    "        else:\n",
    "            x_test.append(t)\n",
    "            y_test.append(y)\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# x_train = np.reshape(x_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "# y_train = np.reshape(y_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "# x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1]))\n",
    "# y_test = np.reshape(y_test, (1, x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "# # print(y_test[-1])\n",
    "x_train, y_train, x_test, y_test = create_data(7, 1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "# print(y_test[-1])\n",
    "# print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "642.9340703168365\n",
      "627.0390414613433\n",
      "616.1930709752745\n",
      "617.5551408259772\n",
      "621.623426084799\n",
      "620.6316440890741\n",
      "618.6411731370952\n",
      "621.2584252656378\n",
      "625.4142454154462\n",
      "629.5416182583996\n",
      "633.5350609310615\n",
      "636.8481325524093\n",
      "637.8723200468373\n",
      "636.0526255786066\n"
     ]
    }
   ],
   "source": [
    "#mean with before days\n",
    "def mean(max_len):\n",
    "    err = 0\n",
    "    predict = 0\n",
    "    count = []\n",
    "    outputs = data['備轉'][0]\n",
    "    for i in data['備轉']:\n",
    "        if len(count) > max_len:\n",
    "            count.pop(0)\n",
    "        if len(count) > 0:\n",
    "            outputs = i\n",
    "            predict = sum(count)/len(count)\n",
    "            err += (outputs - predict)**2\n",
    "        count.append(outputs)\n",
    "    return math.sqrt(err/len(data))\n",
    "\n",
    "        \n",
    "def predict_mean(max_len):\n",
    "    count = data['備轉'][:max_len]\n",
    "    count = count.values.tolist()\n",
    "    predict_list = []\n",
    "    for i in range(7):\n",
    "        predict = sum(count) / max_len\n",
    "        predict_list.append(predict)\n",
    "        count = np.de\n",
    "        count.append(predict)\n",
    "    return predict_list\n",
    "for i in range(15):\n",
    "    print(mean(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past 1 future 1 147.17857142857142\n",
      "past 1 future 2 174.88777477607283\n",
      "past 1 future 3 192.2024142435736\n",
      "past 1 future 4 200.61268519473688\n",
      "past 1 future 5 205.4574970999419\n",
      "past 1 future 6 204.46915191086103\n",
      "past 1 future 7 208.64931358349943\n",
      "past 2 future 1 149.39285714285714\n",
      "past 2 future 2 172.22694388446624\n",
      "past 2 future 3 185.78040835445321\n",
      "past 2 future 4 192.85902368500973\n",
      "past 2 future 5 194.56401497240628\n",
      "past 2 future 6 193.01547473302065\n",
      "past 2 future 7 194.44542292522985\n",
      "past 3 future 1 138.9642857142857\n",
      "past 3 future 2 170.36959659740302\n",
      "past 3 future 3 181.6101492461706\n",
      "past 3 future 4 184.42607349554638\n",
      "past 3 future 5 185.57449668031924\n",
      "past 3 future 6 184.79461222622655\n",
      "past 3 future 7 184.42008064513536\n",
      "past 4 future 1 141.99107142857142\n",
      "past 4 future 2 172.37699226483738\n",
      "past 4 future 3 180.44131475638298\n",
      "past 4 future 4 183.11675251083264\n",
      "past 4 future 5 182.42475258807352\n",
      "past 4 future 6 180.3342507695543\n",
      "past 4 future 7 179.06038490334777\n",
      "past 5 future 1 144.64285714285717\n",
      "past 5 future 2 168.81714833454947\n",
      "past 5 future 3 176.48645455145802\n",
      "past 5 future 4 180.77639081577496\n",
      "past 5 future 5 180.94884681717326\n",
      "past 5 future 6 178.00183810103545\n",
      "past 5 future 7 176.83239608960963\n",
      "past 6 future 1 135.47619047619042\n",
      "past 6 future 2 160.01162199314325\n",
      "past 6 future 3 168.83643311062633\n",
      "past 6 future 4 173.56464315256045\n",
      "past 6 future 5 175.01444198533156\n",
      "past 6 future 6 173.48729454194316\n",
      "past 6 future 7 173.00921614737624\n",
      "past 7 future 1 130.73979591836735\n",
      "past 7 future 2 150.77177645444561\n",
      "past 7 future 3 158.09718697900618\n",
      "past 7 future 4 161.9881184285627\n",
      "past 7 future 5 163.6248664197952\n",
      "past 7 future 6 162.88016300222694\n",
      "past 7 future 7 162.7971039133341\n",
      "past 8 future 1 131.49107142857142\n",
      "past 8 future 2 149.7794294832756\n",
      "past 8 future 3 155.1727786599844\n",
      "past 8 future 4 158.56841208255653\n",
      "past 8 future 5 159.9883907191473\n",
      "past 8 future 6 159.24453479423232\n",
      "past 8 future 7 159.1675186223494\n",
      "past 9 future 1 135.12698412698413\n",
      "past 9 future 2 152.2689373156473\n",
      "past 9 future 3 156.3200046599815\n",
      "past 9 future 4 158.54064958649954\n",
      "past 9 future 5 159.22993911580912\n",
      "past 9 future 6 158.33953426828538\n",
      "past 9 future 7 158.360939617407\n",
      "past 10 future 1 136.57142857142853\n",
      "past 10 future 2 153.12438064177528\n",
      "past 10 future 3 156.17884224767062\n",
      "past 10 future 4 157.46742828034147\n",
      "past 10 future 5 157.66745647085992\n",
      "past 10 future 6 156.53070764252305\n",
      "past 10 future 7 156.3145529968594\n",
      "past 11 future 1 139.69480519480524\n",
      "past 11 future 2 156.3979547181977\n",
      "past 11 future 3 159.4568699229533\n",
      "past 11 future 4 160.53905464843413\n",
      "past 11 future 5 160.6092986387596\n",
      "past 11 future 6 159.2696614800109\n",
      "past 11 future 7 158.73447791253534\n",
      "past 12 future 1 142.11607142857144\n",
      "past 12 future 2 157.87973694411474\n",
      "past 12 future 3 160.80207312816202\n",
      "past 12 future 4 162.06814947068324\n",
      "past 12 future 5 162.00494986811765\n",
      "past 12 future 6 160.6695450201582\n",
      "past 12 future 7 159.97297914210324\n",
      "past 13 future 1 141.16483516483513\n",
      "past 13 future 2 155.0368110231972\n",
      "past 13 future 3 158.63286908440705\n",
      "past 13 future 4 160.2587133670215\n",
      "past 13 future 5 160.55006516484332\n",
      "past 13 future 6 159.58442714613014\n",
      "past 13 future 7 158.99777866580365\n"
     ]
    }
   ],
   "source": [
    "def mean_model(x_train, y_train, x_test, y_test, max_past_len, max_future_len, mode):\n",
    "    #test mode\n",
    "    if mode == \"test\":\n",
    "        count = data['備轉'][:max_past_len]\n",
    "        count = count.values.tolist()\n",
    "        predict_list = []\n",
    "        for i in range(7):\n",
    "            predict = sum(count) / max_past_len\n",
    "            predict_list.append(predict)\n",
    "            count = count.pop(0)\n",
    "            count.append(predict)\n",
    "        return predict_list\n",
    "    #train mode\n",
    "    else:\n",
    "        err = 0\n",
    "        result = []\n",
    "        for i, j in zip(x_test, y_test):\n",
    "            count = [k[0] for k in i]\n",
    "            for h in j:\n",
    "                predict = sum(count)/len(count)\n",
    "                err += (predict-h)**2\n",
    "                count.pop(0)\n",
    "                count.append(predict)\n",
    "            err = math.sqrt(err/max_future_len)\n",
    "            result.append(err)\n",
    "            err = 0\n",
    "            \n",
    "        return sum(result)/len(result)\n",
    "for i in range(1, 14):\n",
    "    for j in range(1, 8):\n",
    "        x_train, y_train, x_test, y_test = create_data(i, j)\n",
    "\n",
    "        print(\"past\",i, \"future\", j, mean_model(x_train, y_train, x_test, y_test, i, j, \"train\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_model(x_train, y_train, x_test, y_test, max_len, mode):\n",
    "    #test mode\n",
    "    if mode == \"test\":\n",
    "        count = data['備轉'][:max_len]\n",
    "        count = count.values.tolist()\n",
    "        predict_list = []\n",
    "        for i in range(7):\n",
    "            predict = sum(count) / max_len\n",
    "            predict_list.append(predict)\n",
    "            count = count.pop(0)\n",
    "            count.append(predict)\n",
    "        return predict_list\n",
    "    #train mode\n",
    "    else:\n",
    "        err = 0\n",
    "        for i,j in zip(x_test, y_test):\n",
    "            i = i[0]\n",
    "            predict = i.mean()\n",
    "            err += (predict-j)**2\n",
    "        return math.sqrt(err/len(x_test))\n",
    "    for i in range(1, 11):\n",
    "        x_train, y_train, x_test, y_test = create_data(i, 1)\n",
    "        print(i, mean_model(x_train, y_train, x_test, y_test, i, \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2599, 8, 1)\n",
      "(2599, 1)\n",
      "(28, 8, 1)\n",
      "(28, 1)\n",
      "(8, 1)\n"
     ]
    }
   ],
   "source": [
    " def create_nor_data(past = 7, future = 7):\n",
    "    # model = build()\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    print(past)\n",
    "    print(len(data))\n",
    "    for i in range(past+future, len(data)+1):\n",
    "        t = data.iloc[i-past-future:i-future][['backup']]\n",
    "        y = data['備轉'].iloc[i-future:i]\n",
    "        if i < 2600:\n",
    "            x_train.append(t)\n",
    "            y_train.append(y)\n",
    "        else:\n",
    "            x_test.append(t)\n",
    "            y_test.append(y)\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "# x_train = np.reshape(x_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "# y_train = np.reshape(y_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "\n",
    "# x_test = np.reshape(x_test, (1, x_test.shape[0], x_test.shape[1]))\n",
    "# y_test = np.reshape(y_test, (1, x_test.shape[0], x_test.shape[1]))\n",
    "\n",
    "# print(y_test[-1])\n",
    "x_train, y_train, x_test, y_test = create_data(8, 1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_test[-1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildmanytomany(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2], return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(1)))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, input_shape=(day, 2), return_sequences=True))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "#     model.add(Dropout(0.2))\n",
    "    # output shape: (1, 1)\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=50,  return_sequences=True))\n",
    "    # output shape: (1, 1)\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(units = 1))\n",
    "    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 7, 10)             480       \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 7, 1)              11        \n",
      "=================================================================\n",
      "Total params: 491\n",
      "Trainable params: 491\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(2586, 7, 1)\n",
      "Epoch 1/650\n",
      "81/81 [==============================] - 2s 3ms/step - loss: 9926764.1463\n",
      "Epoch 2/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9671203.5244\n",
      "Epoch 3/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9712187.1463\n",
      "Epoch 4/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9742854.4146\n",
      "Epoch 5/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9797463.3293\n",
      "Epoch 6/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9632698.8476\n",
      "Epoch 7/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9804598.7561\n",
      "Epoch 8/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9760716.5244\n",
      "Epoch 9/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9769735.3415\n",
      "Epoch 10/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9937182.1463\n",
      "Epoch 11/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9648697.8659\n",
      "Epoch 12/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9720424.4024\n",
      "Epoch 13/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9725543.1341\n",
      "Epoch 14/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9829425.4634\n",
      "Epoch 15/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9839799.2805\n",
      "Epoch 16/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9719977.5610\n",
      "Epoch 17/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9772806.6098\n",
      "Epoch 18/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9789979.3780\n",
      "Epoch 19/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9501417.3537\n",
      "Epoch 20/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9582579.6037\n",
      "Epoch 21/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9725986.1707\n",
      "Epoch 22/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9901750.2439\n",
      "Epoch 23/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9734117.1098\n",
      "Epoch 24/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9896725.2927\n",
      "Epoch 25/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9774048.8415\n",
      "Epoch 26/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9679447.6707\n",
      "Epoch 27/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9763375.9878\n",
      "Epoch 28/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9735355.8415\n",
      "Epoch 29/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9682221.9390\n",
      "Epoch 30/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9775637.0366\n",
      "Epoch 31/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9724536.5610\n",
      "Epoch 32/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9710957.7805\n",
      "Epoch 33/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9781158.4512\n",
      "Epoch 34/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9693667.8537\n",
      "Epoch 35/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9755671.5732\n",
      "Epoch 36/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9799434.9634\n",
      "Epoch 37/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9832284.1951\n",
      "Epoch 38/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9802313.6098\n",
      "Epoch 39/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9664141.5244\n",
      "Epoch 40/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9699955.0610\n",
      "Epoch 41/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9804444.0122\n",
      "Epoch 42/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9831783.2927\n",
      "Epoch 43/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9726967.2195\n",
      "Epoch 44/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9486101.5793\n",
      "Epoch 45/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9828826.1707\n",
      "Epoch 46/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9622118.8780\n",
      "Epoch 47/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9733453.1098\n",
      "Epoch 48/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9744044.8902\n",
      "Epoch 49/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9783604.4146\n",
      "Epoch 50/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9665812.1341\n",
      "Epoch 51/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9667930.8780\n",
      "Epoch 52/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9825478.5976\n",
      "Epoch 53/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9674036.8415\n",
      "Epoch 54/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9641540.6585\n",
      "Epoch 55/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9909212.0610\n",
      "Epoch 56/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9646698.9146\n",
      "Epoch 57/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9702714.0122\n",
      "Epoch 58/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9752351.0732\n",
      "Epoch 59/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9576169.7866\n",
      "Epoch 60/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9825131.9878\n",
      "Epoch 61/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9821682.8659\n",
      "Epoch 62/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9620407.6951\n",
      "Epoch 63/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9599061.2073\n",
      "Epoch 64/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9761970.2683\n",
      "Epoch 65/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9871168.7561\n",
      "Epoch 66/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9604830.8415\n",
      "Epoch 67/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9619648.8415\n",
      "Epoch 68/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9623422.8049\n",
      "Epoch 69/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9518555.6829\n",
      "Epoch 70/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9496999.6159\n",
      "Epoch 71/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9554316.7073\n",
      "Epoch 72/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9669921.6098\n",
      "Epoch 73/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9727607.5610\n",
      "Epoch 74/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9662978.3902\n",
      "Epoch 75/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9727414.0366\n",
      "Epoch 76/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9722653.4268\n",
      "Epoch 77/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9596344.5976\n",
      "Epoch 78/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9785404.1829\n",
      "Epoch 79/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9407700.6220\n",
      "Epoch 80/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9861285.8171\n",
      "Epoch 81/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9754758.8049\n",
      "Epoch 82/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9709331.0122\n",
      "Epoch 83/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9692043.1951\n",
      "Epoch 84/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9629725.0488\n",
      "Epoch 85/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9503854.3659\n",
      "Epoch 86/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9676878.4146\n",
      "Epoch 87/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9542338.1098\n",
      "Epoch 88/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 3ms/step - loss: 9579918.4024\n",
      "Epoch 89/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9754824.0854\n",
      "Epoch 90/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9876151.4390\n",
      "Epoch 91/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9444548.1220\n",
      "Epoch 92/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9951631.7561\n",
      "Epoch 93/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9470829.1463\n",
      "Epoch 94/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9612766.0122\n",
      "Epoch 95/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9787644.0122\n",
      "Epoch 96/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9616190.3293\n",
      "Epoch 97/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9560022.8415\n",
      "Epoch 98/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9645957.3293\n",
      "Epoch 99/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9599779.9634\n",
      "Epoch 100/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9892055.6220\n",
      "Epoch 101/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9432926.7073\n",
      "Epoch 102/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9592157.7927\n",
      "Epoch 103/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9699489.3780\n",
      "Epoch 104/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9532265.0061\n",
      "Epoch 105/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9435953.9268\n",
      "Epoch 106/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9746870.7439\n",
      "Epoch 107/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9651547.0854\n",
      "Epoch 108/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9479534.6463\n",
      "Epoch 109/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9551908.6098\n",
      "Epoch 110/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9769165.9390\n",
      "Epoch 111/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9599025.1463\n",
      "Epoch 112/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9606610.5976\n",
      "Epoch 113/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9461078.6463\n",
      "Epoch 114/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9592592.7439\n",
      "Epoch 115/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9578621.1341\n",
      "Epoch 116/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9547263.4634\n",
      "Epoch 117/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9635441.7805\n",
      "Epoch 118/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9395460.6585\n",
      "Epoch 119/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9356478.9329\n",
      "Epoch 120/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9530633.5000\n",
      "Epoch 121/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9495956.8415\n",
      "Epoch 122/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9681788.9878\n",
      "Epoch 123/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9821195.6341\n",
      "Epoch 124/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9602039.3171\n",
      "Epoch 125/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9619880.1829\n",
      "Epoch 126/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9801601.2927\n",
      "Epoch 127/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9340471.8902\n",
      "Epoch 128/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9716017.7561\n",
      "Epoch 129/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9533941.5488\n",
      "Epoch 130/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9647187.6951\n",
      "Epoch 131/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9619037.4512\n",
      "Epoch 132/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9751583.6463\n",
      "Epoch 133/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9401121.3659\n",
      "Epoch 134/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9652818.0000\n",
      "Epoch 135/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9668170.1707\n",
      "Epoch 136/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9375249.4695\n",
      "Epoch 137/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9456527.0061\n",
      "Epoch 138/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9462179.7683\n",
      "Epoch 139/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9651854.7927\n",
      "Epoch 140/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9360423.3415\n",
      "Epoch 141/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9606850.8293\n",
      "Epoch 142/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9332102.3049\n",
      "Epoch 143/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9430371.7012\n",
      "Epoch 144/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9609523.7927\n",
      "Epoch 145/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9480620.7683\n",
      "Epoch 146/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9543135.3171\n",
      "Epoch 147/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9672882.6463\n",
      "Epoch 148/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9624256.9756\n",
      "Epoch 149/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9525920.5488\n",
      "Epoch 150/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9514657.9146\n",
      "Epoch 151/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9706574.5244\n",
      "Epoch 152/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9591784.5244\n",
      "Epoch 153/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9657441.5854\n",
      "Epoch 154/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9645617.4024\n",
      "Epoch 155/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9434926.6890\n",
      "Epoch 156/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9405901.8415\n",
      "Epoch 157/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9528713.2439\n",
      "Epoch 158/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9461967.2073\n",
      "Epoch 159/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9415627.6220\n",
      "Epoch 160/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9501885.9878\n",
      "Epoch 161/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9401861.6341\n",
      "Epoch 162/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9713228.2683\n",
      "Epoch 163/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9256749.5854\n",
      "Epoch 164/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9397026.5854\n",
      "Epoch 165/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9675983.5610\n",
      "Epoch 166/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9567037.4146\n",
      "Epoch 167/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9468771.5000\n",
      "Epoch 168/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9561062.7439\n",
      "Epoch 169/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9517161.1707\n",
      "Epoch 170/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9409641.0732\n",
      "Epoch 171/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9477520.1402\n",
      "Epoch 172/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9675058.3659\n",
      "Epoch 173/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9657896.3293\n",
      "Epoch 174/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9544877.9268\n",
      "Epoch 175/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9490711.9207\n",
      "Epoch 176/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9470849.9390\n",
      "Epoch 177/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9405045.5000\n",
      "Epoch 178/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9457990.1098\n",
      "Epoch 179/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9516740.0976\n",
      "Epoch 180/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9513511.0244\n",
      "Epoch 181/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9712171.7195\n",
      "Epoch 182/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9210197.3232\n",
      "Epoch 183/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9340255.2439\n",
      "Epoch 184/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9593636.9024\n",
      "Epoch 185/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9702320.8171\n",
      "Epoch 186/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9607733.9390\n",
      "Epoch 187/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9492650.1341\n",
      "Epoch 188/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9620181.7195\n",
      "Epoch 189/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9558468.6463\n",
      "Epoch 190/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9434693.0488\n",
      "Epoch 191/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9500141.9024\n",
      "Epoch 192/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9483036.8720\n",
      "Epoch 193/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9446629.0000\n",
      "Epoch 194/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9424835.4634\n",
      "Epoch 195/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9278229.3963\n",
      "Epoch 196/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9435666.6463\n",
      "Epoch 197/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9446467.2439\n",
      "Epoch 198/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9610609.3171\n",
      "Epoch 199/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9455624.8232\n",
      "Epoch 200/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9495411.7439\n",
      "Epoch 201/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9412015.4390\n",
      "Epoch 202/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9478899.5122\n",
      "Epoch 203/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9200517.7073\n",
      "Epoch 204/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9397634.6341\n",
      "Epoch 205/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9482775.9634\n",
      "Epoch 206/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9373546.9634\n",
      "Epoch 207/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9834388.1463\n",
      "Epoch 208/650\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 9359394.1463\n",
      "Epoch 209/650\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 9582348.3415\n",
      "Epoch 210/650\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 9278813.2622\n",
      "Epoch 211/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9494891.1585\n",
      "Epoch 212/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9332556.4024\n",
      "Epoch 213/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9472663.2073\n",
      "Epoch 214/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9454927.9024\n",
      "Epoch 215/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9387100.9878\n",
      "Epoch 216/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9214535.0793\n",
      "Epoch 217/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9438100.1220\n",
      "Epoch 218/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9294430.8476\n",
      "Epoch 219/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9532783.6951\n",
      "Epoch 220/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9410565.0122\n",
      "Epoch 221/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9488221.4146\n",
      "Epoch 222/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9443425.6951\n",
      "Epoch 223/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9331614.8659\n",
      "Epoch 224/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9478400.0488\n",
      "Epoch 225/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9272160.9817\n",
      "Epoch 226/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9507979.9878\n",
      "Epoch 227/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9432593.6220\n",
      "Epoch 228/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9450768.4878\n",
      "Epoch 229/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9644509.2439\n",
      "Epoch 230/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9644403.7561\n",
      "Epoch 231/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9360429.2683\n",
      "Epoch 232/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9517735.6829\n",
      "Epoch 233/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9288940.3902\n",
      "Epoch 234/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9345249.7195\n",
      "Epoch 235/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9483703.7805\n",
      "Epoch 236/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9427837.5610\n",
      "Epoch 237/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9353545.5122\n",
      "Epoch 238/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9405011.6707\n",
      "Epoch 239/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9529667.3171\n",
      "Epoch 240/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9571396.5366\n",
      "Epoch 241/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9477082.0732\n",
      "Epoch 242/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9100841.7561\n",
      "Epoch 243/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9357446.7805\n",
      "Epoch 244/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9318814.6159\n",
      "Epoch 245/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9432757.2378\n",
      "Epoch 246/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9519393.5000\n",
      "Epoch 247/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9385581.2561\n",
      "Epoch 248/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9242019.5854\n",
      "Epoch 249/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9411359.5854\n",
      "Epoch 250/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9498440.8537\n",
      "Epoch 251/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9393878.2683\n",
      "Epoch 252/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9242247.0244\n",
      "Epoch 253/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9217842.7805\n",
      "Epoch 254/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9527248.5000\n",
      "Epoch 255/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9395859.6829\n",
      "Epoch 256/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9387309.3415\n",
      "Epoch 257/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9384910.2805\n",
      "Epoch 258/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9468030.4146\n",
      "Epoch 259/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9366056.4878\n",
      "Epoch 260/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9207421.6098\n",
      "Epoch 261/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9554911.6707\n",
      "Epoch 262/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9163042.0854\n",
      "Epoch 263/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9309100.2927\n",
      "Epoch 264/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9388603.3902\n",
      "Epoch 265/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9195682.8537\n",
      "Epoch 266/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9468524.4878\n",
      "Epoch 267/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9241709.5366\n",
      "Epoch 268/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9275713.4024\n",
      "Epoch 269/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9588787.7317\n",
      "Epoch 270/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9521091.2927\n",
      "Epoch 271/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9095351.4878\n",
      "Epoch 272/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9427119.7805\n",
      "Epoch 273/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9365627.6220\n",
      "Epoch 274/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 3ms/step - loss: 9488415.2195\n",
      "Epoch 275/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9213085.7134\n",
      "Epoch 276/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9331691.9878\n",
      "Epoch 277/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9270762.2439\n",
      "Epoch 278/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9180096.9695\n",
      "Epoch 279/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9278555.2317\n",
      "Epoch 280/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9253529.3598\n",
      "Epoch 281/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9267273.9390\n",
      "Epoch 282/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9387151.5976\n",
      "Epoch 283/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9272126.2195\n",
      "Epoch 284/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9128347.4695\n",
      "Epoch 285/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9252492.5732\n",
      "Epoch 286/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9283904.9634\n",
      "Epoch 287/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9450951.7683\n",
      "Epoch 288/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9275658.2561\n",
      "Epoch 289/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9418252.7561\n",
      "Epoch 290/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9486352.5000\n",
      "Epoch 291/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9385023.5488\n",
      "Epoch 292/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9295903.4390\n",
      "Epoch 293/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9175194.8537\n",
      "Epoch 294/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9270535.3293\n",
      "Epoch 295/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9368181.2195\n",
      "Epoch 296/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9285476.6280\n",
      "Epoch 297/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9230738.7439\n",
      "Epoch 298/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9156886.9146\n",
      "Epoch 299/650\n",
      "81/81 [==============================] - 1s 8ms/step - loss: 9133188.8415\n",
      "Epoch 300/650\n",
      "81/81 [==============================] - 1s 13ms/step - loss: 9176655.6159\n",
      "Epoch 301/650\n",
      "81/81 [==============================] - 1s 14ms/step - loss: 9366350.6098\n",
      "Epoch 302/650\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 9306708.5000\n",
      "Epoch 303/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9183224.2683\n",
      "Epoch 304/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9226331.4146\n",
      "Epoch 305/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9299146.1220\n",
      "Epoch 306/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9146512.8780\n",
      "Epoch 307/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9383623.0610\n",
      "Epoch 308/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9133985.2927\n",
      "Epoch 309/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9464543.5000\n",
      "Epoch 310/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9404541.2439\n",
      "Epoch 311/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9248332.2744\n",
      "Epoch 312/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9295043.1951\n",
      "Epoch 313/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8893663.9451\n",
      "Epoch 314/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9083521.8780\n",
      "Epoch 315/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9250931.6341\n",
      "Epoch 316/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9296116.1098\n",
      "Epoch 317/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9223866.2683\n",
      "Epoch 318/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9323668.6220\n",
      "Epoch 319/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9008190.7622\n",
      "Epoch 320/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9310372.8537\n",
      "Epoch 321/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9189157.0061\n",
      "Epoch 322/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9390338.6951\n",
      "Epoch 323/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9172379.2683\n",
      "Epoch 324/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9229902.6463\n",
      "Epoch 325/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9159179.1220\n",
      "Epoch 326/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9068226.5244\n",
      "Epoch 327/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9230787.6829\n",
      "Epoch 328/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9112204.4817\n",
      "Epoch 329/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9284543.4634\n",
      "Epoch 330/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9274608.2317\n",
      "Epoch 331/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9341371.2683\n",
      "Epoch 332/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9186812.0000\n",
      "Epoch 333/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9225058.8415\n",
      "Epoch 334/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9366670.5976\n",
      "Epoch 335/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9141450.9634\n",
      "Epoch 336/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9426343.2683\n",
      "Epoch 337/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9151162.8049\n",
      "Epoch 338/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9319035.2317\n",
      "Epoch 339/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9179152.7439\n",
      "Epoch 340/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9107045.0610\n",
      "Epoch 341/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9231786.6829\n",
      "Epoch 342/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9199000.6280\n",
      "Epoch 343/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9052423.4817\n",
      "Epoch 344/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9191162.3963\n",
      "Epoch 345/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9325332.1585\n",
      "Epoch 346/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8904253.2439\n",
      "Epoch 347/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9048518.6037\n",
      "Epoch 348/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9213974.7683\n",
      "Epoch 349/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9165268.0610\n",
      "Epoch 350/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9295737.4146\n",
      "Epoch 351/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9172983.1463\n",
      "Epoch 352/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9151192.0610\n",
      "Epoch 353/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9289119.8293\n",
      "Epoch 354/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9393927.3902\n",
      "Epoch 355/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9039843.6098\n",
      "Epoch 356/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9186509.1463\n",
      "Epoch 357/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9162620.2744\n",
      "Epoch 358/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9445648.2317\n",
      "Epoch 359/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9106986.9512\n",
      "Epoch 360/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9016552.1037\n",
      "Epoch 361/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9047631.8293\n",
      "Epoch 362/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9295446.1463\n",
      "Epoch 363/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8978581.3537\n",
      "Epoch 364/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9258584.3659\n",
      "Epoch 365/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9176992.3049\n",
      "Epoch 366/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9075718.6098\n",
      "Epoch 367/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9232825.7805\n",
      "Epoch 368/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9310641.5244\n",
      "Epoch 369/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9191657.6707\n",
      "Epoch 370/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8981002.4817\n",
      "Epoch 371/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9102055.1463\n",
      "Epoch 372/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9287477.6341\n",
      "Epoch 373/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9156923.4756\n",
      "Epoch 374/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9046095.5976\n",
      "Epoch 375/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9353473.0732\n",
      "Epoch 376/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9212286.8780\n",
      "Epoch 377/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9359924.1951\n",
      "Epoch 378/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9167156.0244\n",
      "Epoch 379/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9257457.9268\n",
      "Epoch 380/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8853249.1585\n",
      "Epoch 381/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8901251.4024\n",
      "Epoch 382/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9044208.7988\n",
      "Epoch 383/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9095019.5122\n",
      "Epoch 384/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9342424.9146\n",
      "Epoch 385/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9349134.8293\n",
      "Epoch 386/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9186706.0000\n",
      "Epoch 387/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9131079.4573\n",
      "Epoch 388/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9345482.8293\n",
      "Epoch 389/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9090978.1585\n",
      "Epoch 390/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9124650.4939\n",
      "Epoch 391/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8951375.4634\n",
      "Epoch 392/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8989343.4878\n",
      "Epoch 393/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9085452.9512\n",
      "Epoch 394/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9010576.0366\n",
      "Epoch 395/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9147202.6951\n",
      "Epoch 396/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9180332.6159\n",
      "Epoch 397/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9389438.6463\n",
      "Epoch 398/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8942354.5244\n",
      "Epoch 399/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9000793.0854\n",
      "Epoch 400/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9225225.6951\n",
      "Epoch 401/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9224732.2195\n",
      "Epoch 402/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9060984.5976\n",
      "Epoch 403/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9203012.9756\n",
      "Epoch 404/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9265762.5976\n",
      "Epoch 405/650\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 8960407.3659\n",
      "Epoch 406/650\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 9174863.5549\n",
      "Epoch 407/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9130859.3415\n",
      "Epoch 408/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8880940.2622\n",
      "Epoch 409/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9103086.6951\n",
      "Epoch 410/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9074299.0915\n",
      "Epoch 411/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9156800.4512\n",
      "Epoch 412/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9212772.2317\n",
      "Epoch 413/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9245773.4878\n",
      "Epoch 414/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9214777.4146\n",
      "Epoch 415/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8997471.2561\n",
      "Epoch 416/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9194605.4390\n",
      "Epoch 417/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9104492.9390\n",
      "Epoch 418/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9234047.0122\n",
      "Epoch 419/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9132085.8720\n",
      "Epoch 420/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8988575.1524\n",
      "Epoch 421/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8992836.1585\n",
      "Epoch 422/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9152338.0183\n",
      "Epoch 423/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9176607.3902\n",
      "Epoch 424/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9120277.9146\n",
      "Epoch 425/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9086683.6463\n",
      "Epoch 426/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9000171.7805\n",
      "Epoch 427/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8979206.3476\n",
      "Epoch 428/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9107495.7439\n",
      "Epoch 429/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9061947.5000\n",
      "Epoch 430/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9240531.0976\n",
      "Epoch 431/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9049812.6707\n",
      "Epoch 432/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8725472.3171\n",
      "Epoch 433/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9033591.1890\n",
      "Epoch 434/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9138723.8780\n",
      "Epoch 435/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8932787.2500\n",
      "Epoch 436/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9147843.6463\n",
      "Epoch 437/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9043272.6341\n",
      "Epoch 438/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9045035.0122\n",
      "Epoch 439/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9008351.1220\n",
      "Epoch 440/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8959691.7683\n",
      "Epoch 441/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9124227.3902\n",
      "Epoch 442/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9191633.2439\n",
      "Epoch 443/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9118222.2195\n",
      "Epoch 444/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9126854.3537\n",
      "Epoch 445/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9012288.6951\n",
      "Epoch 446/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9149448.2805\n",
      "Epoch 447/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9153622.8537\n",
      "Epoch 448/650\n",
      "81/81 [==============================] - 1s 11ms/step - loss: 9155745.8659\n",
      "Epoch 449/650\n",
      "81/81 [==============================] - 1s 12ms/step - loss: 9083003.6280\n",
      "Epoch 450/650\n",
      "81/81 [==============================] - 1s 6ms/step - loss: 9077969.3780\n",
      "Epoch 451/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9205426.2927\n",
      "Epoch 452/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8877995.9451\n",
      "Epoch 453/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9035338.9146\n",
      "Epoch 454/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9108341.2561\n",
      "Epoch 455/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8980352.1951\n",
      "Epoch 456/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8982334.5244\n",
      "Epoch 457/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9099420.8171\n",
      "Epoch 458/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9212021.8049\n",
      "Epoch 459/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8973787.8902\n",
      "Epoch 460/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 3ms/step - loss: 8778127.3415\n",
      "Epoch 461/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9030104.8537\n",
      "Epoch 462/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9116034.7805\n",
      "Epoch 463/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8901605.6890\n",
      "Epoch 464/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8833604.3841\n",
      "Epoch 465/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9050961.0366\n",
      "Epoch 466/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9114736.3780\n",
      "Epoch 467/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8986064.3110\n",
      "Epoch 468/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8924691.1098\n",
      "Epoch 469/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9079195.5122\n",
      "Epoch 470/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8713715.6341\n",
      "Epoch 471/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9115251.1585\n",
      "Epoch 472/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8866382.9817\n",
      "Epoch 473/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9004361.4268\n",
      "Epoch 474/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9165067.0976\n",
      "Epoch 475/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8957819.4451\n",
      "Epoch 476/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9079874.7622\n",
      "Epoch 477/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8854879.0061\n",
      "Epoch 478/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9060786.2195\n",
      "Epoch 479/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8986306.5671\n",
      "Epoch 480/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8787589.8537\n",
      "Epoch 481/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9061901.2195\n",
      "Epoch 482/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8901312.5732\n",
      "Epoch 483/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9021323.0122\n",
      "Epoch 484/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9119391.3537\n",
      "Epoch 485/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8947926.0122\n",
      "Epoch 486/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8905116.2012\n",
      "Epoch 487/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8938439.5976\n",
      "Epoch 488/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8710292.2988\n",
      "Epoch 489/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9009294.8293\n",
      "Epoch 490/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8940047.7439\n",
      "Epoch 491/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8968611.5366\n",
      "Epoch 492/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8902683.0915\n",
      "Epoch 493/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8810118.3049\n",
      "Epoch 494/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8905707.8780\n",
      "Epoch 495/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9114124.5610\n",
      "Epoch 496/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9220588.6280\n",
      "Epoch 497/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8991708.4817\n",
      "Epoch 498/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9126266.6585\n",
      "Epoch 499/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9098914.6220\n",
      "Epoch 500/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8892190.7073\n",
      "Epoch 501/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8902728.4573\n",
      "Epoch 502/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8931606.9817\n",
      "Epoch 503/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8851698.3293\n",
      "Epoch 504/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9010393.2927\n",
      "Epoch 505/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8824063.9329\n",
      "Epoch 506/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8980741.4756\n",
      "Epoch 507/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8893502.1524\n",
      "Epoch 508/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9100138.0854\n",
      "Epoch 509/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8838063.9085\n",
      "Epoch 510/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9055009.3049\n",
      "Epoch 511/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9021588.6585\n",
      "Epoch 512/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8996086.9512\n",
      "Epoch 513/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9092859.3537\n",
      "Epoch 514/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9024288.2439\n",
      "Epoch 515/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9091461.5732\n",
      "Epoch 516/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8944398.8537\n",
      "Epoch 517/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8796762.5549\n",
      "Epoch 518/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9042858.7195\n",
      "Epoch 519/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9020047.0244\n",
      "Epoch 520/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8893375.2866\n",
      "Epoch 521/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8747846.9878\n",
      "Epoch 522/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8836259.4695\n",
      "Epoch 523/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9036235.0488\n",
      "Epoch 524/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8979947.5244\n",
      "Epoch 525/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8953647.2683\n",
      "Epoch 526/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9057221.4878\n",
      "Epoch 527/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8705304.2317\n",
      "Epoch 528/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8965221.7439\n",
      "Epoch 529/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9026980.1098\n",
      "Epoch 530/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8917398.5854\n",
      "Epoch 531/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9078318.4024\n",
      "Epoch 532/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8836824.6524\n",
      "Epoch 533/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8954530.5061\n",
      "Epoch 534/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8867596.0610\n",
      "Epoch 535/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8905072.0854\n",
      "Epoch 536/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8815229.3659\n",
      "Epoch 537/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9191939.7073\n",
      "Epoch 538/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8914797.1341\n",
      "Epoch 539/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 9047138.0366\n",
      "Epoch 540/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8806951.6220\n",
      "Epoch 541/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8793158.4878\n",
      "Epoch 542/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8961013.0000\n",
      "Epoch 543/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8851635.5061\n",
      "Epoch 544/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8909461.7805\n",
      "Epoch 545/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8984758.3902\n",
      "Epoch 546/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8877042.6829\n",
      "Epoch 547/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9078693.1341\n",
      "Epoch 548/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9023765.1585\n",
      "Epoch 549/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8933688.6829\n",
      "Epoch 550/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8787453.8598\n",
      "Epoch 551/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8836507.8415\n",
      "Epoch 552/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8892570.6951\n",
      "Epoch 553/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8856027.5488\n",
      "Epoch 554/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8894275.1585\n",
      "Epoch 555/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8934091.9756\n",
      "Epoch 556/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8599348.2622\n",
      "Epoch 557/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9046358.2805\n",
      "Epoch 558/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8755483.7012\n",
      "Epoch 559/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8807977.9024\n",
      "Epoch 560/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8786888.4695\n",
      "Epoch 561/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8739013.4512\n",
      "Epoch 562/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8761005.0976\n",
      "Epoch 563/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8989565.3415\n",
      "Epoch 564/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9001659.9634\n",
      "Epoch 565/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8707307.6098\n",
      "Epoch 566/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8938627.5488\n",
      "Epoch 567/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8752918.4024\n",
      "Epoch 568/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8801448.0244\n",
      "Epoch 569/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8853723.9573\n",
      "Epoch 570/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8882426.4756\n",
      "Epoch 571/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8834240.6951\n",
      "Epoch 572/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9012714.1707\n",
      "Epoch 573/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8896729.0427\n",
      "Epoch 574/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8722375.3476\n",
      "Epoch 575/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8870657.8537\n",
      "Epoch 576/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8758844.2805\n",
      "Epoch 577/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8741276.0061\n",
      "Epoch 578/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8792642.2500\n",
      "Epoch 579/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8779665.4756\n",
      "Epoch 580/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8813000.4268\n",
      "Epoch 581/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8682979.0366\n",
      "Epoch 582/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8878307.2805\n",
      "Epoch 583/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8813670.4878\n",
      "Epoch 584/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8823483.5122\n",
      "Epoch 585/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8623068.0732\n",
      "Epoch 586/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8797792.4268\n",
      "Epoch 587/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8761134.6707\n",
      "Epoch 588/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8804147.5610\n",
      "Epoch 589/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8793916.2256\n",
      "Epoch 590/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8791829.4634\n",
      "Epoch 591/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8674753.3110\n",
      "Epoch 592/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8843175.6463\n",
      "Epoch 593/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8726513.6463\n",
      "Epoch 594/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8861067.6524\n",
      "Epoch 595/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8834238.5488\n",
      "Epoch 596/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8972715.3659\n",
      "Epoch 597/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8694441.2988\n",
      "Epoch 598/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8856720.6951\n",
      "Epoch 599/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8750951.4634\n",
      "Epoch 600/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8901820.9756\n",
      "Epoch 601/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8972301.4512\n",
      "Epoch 602/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8724280.3902\n",
      "Epoch 603/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8906652.7866\n",
      "Epoch 604/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8837130.7317\n",
      "Epoch 605/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8776165.0366\n",
      "Epoch 606/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8988480.5366\n",
      "Epoch 607/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8840824.6585\n",
      "Epoch 608/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 9015016.2927\n",
      "Epoch 609/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8893952.4512\n",
      "Epoch 610/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8863500.4512\n",
      "Epoch 611/650\n",
      "81/81 [==============================] - 0s 5ms/step - loss: 8703427.8110\n",
      "Epoch 612/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8858364.5061\n",
      "Epoch 613/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8710630.6402\n",
      "Epoch 614/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8721915.1159\n",
      "Epoch 615/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8911321.6402\n",
      "Epoch 616/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8806735.7805\n",
      "Epoch 617/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8795807.2805\n",
      "Epoch 618/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8657815.9390\n",
      "Epoch 619/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8815768.6585\n",
      "Epoch 620/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8648244.0549\n",
      "Epoch 621/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8861377.9756\n",
      "Epoch 622/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8778649.8841\n",
      "Epoch 623/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8680009.9146\n",
      "Epoch 624/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8900674.8415\n",
      "Epoch 625/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8695132.4329\n",
      "Epoch 626/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8868561.1098\n",
      "Epoch 627/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8489331.3476\n",
      "Epoch 628/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8594369.4268\n",
      "Epoch 629/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8894193.1829\n",
      "Epoch 630/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8950375.5488\n",
      "Epoch 631/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8617235.1524\n",
      "Epoch 632/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8859129.9573\n",
      "Epoch 633/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8808457.5854\n",
      "Epoch 634/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8715922.4024\n",
      "Epoch 635/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8816420.8659\n",
      "Epoch 636/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8750612.6341\n",
      "Epoch 637/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8551283.9207\n",
      "Epoch 638/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8670331.4756\n",
      "Epoch 639/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8750578.9329\n",
      "Epoch 640/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8772634.1098\n",
      "Epoch 641/650\n",
      "81/81 [==============================] - 1s 7ms/step - loss: 8552106.7927\n",
      "Epoch 642/650\n",
      "81/81 [==============================] - 0s 4ms/step - loss: 8730480.3049\n",
      "Epoch 643/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8730888.7195\n",
      "Epoch 644/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8867317.4878\n",
      "Epoch 645/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8543015.1951\n",
      "Epoch 646/650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81/81 [==============================] - 0s 3ms/step - loss: 8619132.8720\n",
      "Epoch 647/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8536030.2866\n",
      "Epoch 648/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8734249.3293\n",
      "Epoch 649/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8628718.9268\n",
      "Epoch 650/650\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 8745129.3049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9578075190>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = create_data(7, 7)\n",
    "regressor = buildmanytomany(x_train.shape)\n",
    "print(x_train.shape)\n",
    "# 進行訓練\n",
    "regressor.fit(x_train, y_train, epochs = 650)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildManyToOneModel(shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=shape[1], input_dim=shape[2], return_sequences=True))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 10))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2599, 8, 1)\n",
      "Model: \"sequential_47\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_64 (LSTM)               (None, 8, 10)             480       \n",
      "_________________________________________________________________\n",
      "dense_145 (Dense)            (None, 8, 10)             110       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 8, 10)             0         \n",
      "_________________________________________________________________\n",
      "dense_146 (Dense)            (None, 8, 10)             110       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 8, 10)             0         \n",
      "_________________________________________________________________\n",
      "dense_147 (Dense)            (None, 8, 1)              11        \n",
      "=================================================================\n",
      "Total params: 711\n",
      "Trainable params: 711\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/350\n",
      "4/4 [==============================] - 1s 4ms/step - loss: 9732196.6000\n",
      "Epoch 2/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9616186.2000\n",
      "Epoch 3/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9653553.8000\n",
      "Epoch 4/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9593119.2000\n",
      "Epoch 5/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9567013.0000\n",
      "Epoch 6/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9690911.8000\n",
      "Epoch 7/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9637339.0000\n",
      "Epoch 8/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9590892.4000\n",
      "Epoch 9/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9551667.6000\n",
      "Epoch 10/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9603553.2000\n",
      "Epoch 11/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9653693.0000\n",
      "Epoch 12/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9678306.4000\n",
      "Epoch 13/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9654539.8000\n",
      "Epoch 14/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9621392.4000\n",
      "Epoch 15/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9648132.8000\n",
      "Epoch 16/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9634164.6000\n",
      "Epoch 17/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9707943.8000\n",
      "Epoch 18/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9678596.4000\n",
      "Epoch 19/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9647238.2000\n",
      "Epoch 20/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9694519.6000\n",
      "Epoch 21/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9628225.4000\n",
      "Epoch 22/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9656974.6000\n",
      "Epoch 23/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9675293.4000\n",
      "Epoch 24/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9711907.8000\n",
      "Epoch 25/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9654002.0000\n",
      "Epoch 26/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9640500.8000\n",
      "Epoch 27/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9580146.8000\n",
      "Epoch 28/350\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 9598278.8000\n",
      "Epoch 29/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9660715.0000\n",
      "Epoch 30/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9666309.8000\n",
      "Epoch 31/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9638938.0000\n",
      "Epoch 32/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9640303.6000\n",
      "Epoch 33/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9630057.8000\n",
      "Epoch 34/350\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 9542406.2000\n",
      "Epoch 35/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9592679.8000\n",
      "Epoch 36/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9647399.2000\n",
      "Epoch 37/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9630623.8000\n",
      "Epoch 38/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9542289.4000\n",
      "Epoch 39/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9593219.4000\n",
      "Epoch 40/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9537874.6000\n",
      "Epoch 41/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9682545.4000\n",
      "Epoch 42/350\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 9581679.2000\n",
      "Epoch 43/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9614212.4000\n",
      "Epoch 44/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9459667.4000\n",
      "Epoch 45/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9614076.2000\n",
      "Epoch 46/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9661120.0000\n",
      "Epoch 47/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9563477.2000\n",
      "Epoch 48/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9555715.4000\n",
      "Epoch 49/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9605940.0000\n",
      "Epoch 50/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9576467.2000\n",
      "Epoch 51/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9600590.0000\n",
      "Epoch 52/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9587599.0000\n",
      "Epoch 53/350\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 9505180.4000\n",
      "Epoch 54/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9552945.6000\n",
      "Epoch 55/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9545538.6000\n",
      "Epoch 56/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9541971.8000\n",
      "Epoch 57/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9386936.8000\n",
      "Epoch 58/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9494970.6000\n",
      "Epoch 59/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9532061.8000\n",
      "Epoch 60/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9459119.0000\n",
      "Epoch 61/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9590429.6000\n",
      "Epoch 62/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9454429.8000\n",
      "Epoch 63/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9485920.0000\n",
      "Epoch 64/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9520956.2000\n",
      "Epoch 65/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9420196.8000\n",
      "Epoch 66/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9493585.2000\n",
      "Epoch 67/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9409402.6000\n",
      "Epoch 68/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9327298.0000\n",
      "Epoch 69/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9298245.8000\n",
      "Epoch 70/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9467230.6000\n",
      "Epoch 71/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9386166.4000\n",
      "Epoch 72/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9373092.8000\n",
      "Epoch 73/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9407581.6000\n",
      "Epoch 74/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9326819.8000\n",
      "Epoch 75/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9335017.8000\n",
      "Epoch 76/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9283955.4000\n",
      "Epoch 77/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9275331.8000\n",
      "Epoch 78/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9210678.4000\n",
      "Epoch 79/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9319398.6000\n",
      "Epoch 80/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9268425.4000\n",
      "Epoch 81/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9254888.2000\n",
      "Epoch 82/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9213076.8000\n",
      "Epoch 83/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 4ms/step - loss: 9179503.2000\n",
      "Epoch 84/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 9209521.4000\n",
      "Epoch 85/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9207296.0000\n",
      "Epoch 86/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9152551.4000\n",
      "Epoch 87/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9188971.2000\n",
      "Epoch 88/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9136272.6000\n",
      "Epoch 89/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9119201.4000\n",
      "Epoch 90/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9135325.0000\n",
      "Epoch 91/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8972389.2000\n",
      "Epoch 92/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9015495.4000\n",
      "Epoch 93/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8979849.6000\n",
      "Epoch 94/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 9015770.8000\n",
      "Epoch 95/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8950978.8000\n",
      "Epoch 96/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8922444.4000\n",
      "Epoch 97/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8959426.2000\n",
      "Epoch 98/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 8895991.2000\n",
      "Epoch 99/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8898500.6000\n",
      "Epoch 100/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8933203.4000\n",
      "Epoch 101/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8888977.0000\n",
      "Epoch 102/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8805590.2000\n",
      "Epoch 103/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8817776.4000\n",
      "Epoch 104/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8913532.4000\n",
      "Epoch 105/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8808375.0000\n",
      "Epoch 106/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8713110.0000\n",
      "Epoch 107/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8692800.8000\n",
      "Epoch 108/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8674665.2000\n",
      "Epoch 109/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8648625.4000\n",
      "Epoch 110/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8662963.4000\n",
      "Epoch 111/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8598000.2000\n",
      "Epoch 112/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8562237.6000\n",
      "Epoch 113/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8601813.0000\n",
      "Epoch 114/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8559636.2000\n",
      "Epoch 115/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8573603.8000\n",
      "Epoch 116/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8521647.4000\n",
      "Epoch 117/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8447912.2000\n",
      "Epoch 118/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8451737.8000\n",
      "Epoch 119/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8381512.1000\n",
      "Epoch 120/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8405432.9000\n",
      "Epoch 121/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8235806.9000\n",
      "Epoch 122/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8315278.5000\n",
      "Epoch 123/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8249879.1000\n",
      "Epoch 124/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8216101.1000\n",
      "Epoch 125/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8237179.2000\n",
      "Epoch 126/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8162786.5000\n",
      "Epoch 127/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8094699.1000\n",
      "Epoch 128/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8167665.9000\n",
      "Epoch 129/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8000754.5000\n",
      "Epoch 130/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 8107589.0000\n",
      "Epoch 131/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7978571.0000\n",
      "Epoch 132/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7996952.2000\n",
      "Epoch 133/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7932218.6000\n",
      "Epoch 134/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7908879.0000\n",
      "Epoch 135/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7922394.5000\n",
      "Epoch 136/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7789142.0000\n",
      "Epoch 137/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7771710.8000\n",
      "Epoch 138/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7751502.6000\n",
      "Epoch 139/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7651732.2000\n",
      "Epoch 140/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7671076.5000\n",
      "Epoch 141/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7609934.3000\n",
      "Epoch 142/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7543828.9000\n",
      "Epoch 143/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7623560.0000\n",
      "Epoch 144/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7551266.7000\n",
      "Epoch 145/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7507417.1000\n",
      "Epoch 146/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7418381.3000\n",
      "Epoch 147/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7371931.3000\n",
      "Epoch 148/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7401459.3000\n",
      "Epoch 149/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7308853.9000\n",
      "Epoch 150/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7259817.4000\n",
      "Epoch 151/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 7222659.9000\n",
      "Epoch 152/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7186629.7000\n",
      "Epoch 153/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7173150.1000\n",
      "Epoch 154/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7150832.0000\n",
      "Epoch 155/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7034545.5000\n",
      "Epoch 156/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 7023556.2000\n",
      "Epoch 157/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6912440.1000\n",
      "Epoch 158/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6885983.9000\n",
      "Epoch 159/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6912932.3000\n",
      "Epoch 160/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6782986.7000\n",
      "Epoch 161/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6859637.6000\n",
      "Epoch 162/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6746737.7000\n",
      "Epoch 163/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6694860.9000\n",
      "Epoch 164/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6580826.2000\n",
      "Epoch 165/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6572685.7000\n",
      "Epoch 166/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6547706.9000\n",
      "Epoch 167/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6433157.5000\n",
      "Epoch 168/350\n",
      "4/4 [==============================] - 0s 7ms/step - loss: 6432013.6000\n",
      "Epoch 169/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 6363872.7000\n",
      "Epoch 170/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6415622.3000\n",
      "Epoch 171/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6352152.5000\n",
      "Epoch 172/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6220552.9000\n",
      "Epoch 173/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6263083.3000\n",
      "Epoch 174/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6207911.3000\n",
      "Epoch 175/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6136312.1000\n",
      "Epoch 176/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6050818.7000\n",
      "Epoch 177/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 6085070.2000\n",
      "Epoch 178/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 6051621.2000\n",
      "Epoch 179/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5943457.8000\n",
      "Epoch 180/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5935383.9000\n",
      "Epoch 181/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5768137.7000\n",
      "Epoch 182/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5788321.9000\n",
      "Epoch 183/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5742480.8000\n",
      "Epoch 184/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5683150.4000\n",
      "Epoch 185/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5697767.3000\n",
      "Epoch 186/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5583597.4000\n",
      "Epoch 187/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5494740.8000\n",
      "Epoch 188/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 5407740.8000\n",
      "Epoch 189/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5422999.7000\n",
      "Epoch 190/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5463042.8000\n",
      "Epoch 191/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5334115.7000\n",
      "Epoch 192/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5244092.7000\n",
      "Epoch 193/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5234307.3000\n",
      "Epoch 194/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5180411.4000\n",
      "Epoch 195/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5208236.7000\n",
      "Epoch 196/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5050713.0000\n",
      "Epoch 197/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 5028205.6000\n",
      "Epoch 198/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4963173.6000\n",
      "Epoch 199/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4988526.0000\n",
      "Epoch 200/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4816256.5000\n",
      "Epoch 201/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4813075.4000\n",
      "Epoch 202/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4787092.4000\n",
      "Epoch 203/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4685830.9000\n",
      "Epoch 204/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4695163.3000\n",
      "Epoch 205/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4585009.5000\n",
      "Epoch 206/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4591131.0000\n",
      "Epoch 207/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4470283.2000\n",
      "Epoch 208/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4457117.9000\n",
      "Epoch 209/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4486112.3000\n",
      "Epoch 210/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4360802.0000\n",
      "Epoch 211/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4211246.4500\n",
      "Epoch 212/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4361576.7000\n",
      "Epoch 213/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4108383.4500\n",
      "Epoch 214/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4243984.4000\n",
      "Epoch 215/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4101676.0000\n",
      "Epoch 216/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4108513.8000\n",
      "Epoch 217/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4068475.4500\n",
      "Epoch 218/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 4000802.9500\n",
      "Epoch 219/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3932114.8500\n",
      "Epoch 220/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3975015.7500\n",
      "Epoch 221/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3852478.0000\n",
      "Epoch 222/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3852333.0500\n",
      "Epoch 223/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3736808.1500\n",
      "Epoch 224/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3740764.2500\n",
      "Epoch 225/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3678668.3000\n",
      "Epoch 226/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3613073.7500\n",
      "Epoch 227/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3591184.1000\n",
      "Epoch 228/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3527999.1500\n",
      "Epoch 229/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3406105.2500\n",
      "Epoch 230/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3513246.9000\n",
      "Epoch 231/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3382047.9500\n",
      "Epoch 232/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3323545.3500\n",
      "Epoch 233/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3264535.2500\n",
      "Epoch 234/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3195988.0500\n",
      "Epoch 235/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3148430.9000\n",
      "Epoch 236/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3207384.8000\n",
      "Epoch 237/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3143042.1000\n",
      "Epoch 238/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3172832.1000\n",
      "Epoch 239/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 3122567.5000\n",
      "Epoch 240/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2971417.4000\n",
      "Epoch 241/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2928296.4000\n",
      "Epoch 242/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 2947284.2500\n",
      "Epoch 243/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2758474.6500\n",
      "Epoch 244/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2866796.6000\n",
      "Epoch 245/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2659065.5000\n",
      "Epoch 246/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2770698.4500\n",
      "Epoch 247/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2672882.4000\n",
      "Epoch 248/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2519506.0000\n",
      "Epoch 249/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2659844.0500\n",
      "Epoch 250/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2632991.6500\n",
      "Epoch 251/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2480411.0500\n",
      "Epoch 252/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2402870.8500\n",
      "Epoch 253/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2427887.9500\n",
      "Epoch 254/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2398740.7500\n",
      "Epoch 255/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2249334.3500\n",
      "Epoch 256/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2340670.5500\n",
      "Epoch 257/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2235129.6000\n",
      "Epoch 258/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2280333.5000\n",
      "Epoch 259/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2173641.0500\n",
      "Epoch 260/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2245382.1500\n",
      "Epoch 261/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2189213.9000\n",
      "Epoch 262/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2062389.8500\n",
      "Epoch 263/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 2061976.4250\n",
      "Epoch 264/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1953364.2000\n",
      "Epoch 265/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1980641.8250\n",
      "Epoch 266/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1968349.0250\n",
      "Epoch 267/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1945049.2000\n",
      "Epoch 268/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1936583.8750\n",
      "Epoch 269/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1892966.8250\n",
      "Epoch 270/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1840691.2250\n",
      "Epoch 271/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1921224.7500\n",
      "Epoch 272/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1751479.1750\n",
      "Epoch 273/350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 1743619.7750\n",
      "Epoch 274/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1670303.1500\n",
      "Epoch 275/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1689727.8750\n",
      "Epoch 276/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1631817.3500\n",
      "Epoch 277/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1624753.0750\n",
      "Epoch 278/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1591687.0250\n",
      "Epoch 279/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1585654.7000\n",
      "Epoch 280/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1614316.3250\n",
      "Epoch 281/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1488266.9250\n",
      "Epoch 282/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1495857.9750\n",
      "Epoch 283/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1424749.8250\n",
      "Epoch 284/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1405131.6750\n",
      "Epoch 285/350\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1431118.6000\n",
      "Epoch 286/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1323437.4500\n",
      "Epoch 287/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1413352.8250\n",
      "Epoch 288/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1329378.7000\n",
      "Epoch 289/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1284702.1500\n",
      "Epoch 290/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1384395.5500\n",
      "Epoch 291/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1337752.7000\n",
      "Epoch 292/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1165297.3500\n",
      "Epoch 293/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1293667.4500\n",
      "Epoch 294/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1224906.2250\n",
      "Epoch 295/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1148094.4000\n",
      "Epoch 296/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1208640.8750\n",
      "Epoch 297/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1177348.3500\n",
      "Epoch 298/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1108806.7500\n",
      "Epoch 299/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1222247.4750\n",
      "Epoch 300/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1041646.5500\n",
      "Epoch 301/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1135329.8750\n",
      "Epoch 302/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1065959.2750\n",
      "Epoch 303/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1106146.5250\n",
      "Epoch 304/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1028933.9375\n",
      "Epoch 305/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 988774.2500\n",
      "Epoch 306/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 1001417.5375\n",
      "Epoch 307/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 976203.0875\n",
      "Epoch 308/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 942710.3750\n",
      "Epoch 309/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 916392.1625\n",
      "Epoch 310/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 916440.6625\n",
      "Epoch 311/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 934151.5625\n",
      "Epoch 312/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 945152.4625\n",
      "Epoch 313/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 835802.6875\n",
      "Epoch 314/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 876806.8875\n",
      "Epoch 315/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 872163.8250\n",
      "Epoch 316/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 865073.8500\n",
      "Epoch 317/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 774127.6000\n",
      "Epoch 318/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 875683.0500\n",
      "Epoch 319/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 823669.8875\n",
      "Epoch 320/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 849539.1375\n",
      "Epoch 321/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 810469.3125\n",
      "Epoch 322/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 844010.7375\n",
      "Epoch 323/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 771137.2125\n",
      "Epoch 324/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 798861.6875\n",
      "Epoch 325/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 723574.7000\n",
      "Epoch 326/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 736824.7375\n",
      "Epoch 327/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 728862.6375\n",
      "Epoch 328/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 755860.2000\n",
      "Epoch 329/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 706186.7125\n",
      "Epoch 330/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 745523.4875\n",
      "Epoch 331/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 713706.5375\n",
      "Epoch 332/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 773255.2250\n",
      "Epoch 333/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 701102.5000\n",
      "Epoch 334/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 661732.6875\n",
      "Epoch 335/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 683825.0625\n",
      "Epoch 336/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 678623.3500\n",
      "Epoch 337/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 659265.0625\n",
      "Epoch 338/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 664790.1250\n",
      "Epoch 339/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 676756.0750\n",
      "Epoch 340/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 634158.8562\n",
      "Epoch 341/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 670118.0875\n",
      "Epoch 342/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 629049.4875\n",
      "Epoch 343/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 634043.0875\n",
      "Epoch 344/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 661795.1125\n",
      "Epoch 345/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 664360.1500\n",
      "Epoch 346/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 627538.1500\n",
      "Epoch 347/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 592356.6875\n",
      "Epoch 348/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 570113.2250\n",
      "Epoch 349/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 574232.6250\n",
      "Epoch 350/350\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 571640.1875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f1d532a9ca0>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = create_data(8, 1)\n",
    "print(x_train.shape)\n",
    "regressor = buildManyToOneModel(x_train.shape)\n",
    "# 進行訓練\n",
    "regressor.fit(x_train[-100:], y_train[-100:], epochs = 350)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[29110.]\n",
      "  [26450.]\n",
      "  [30020.]\n",
      "  [28240.]\n",
      "  [29070.]\n",
      "  [28850.]\n",
      "  [29750.]\n",
      "  [31390.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "337.75171169070336\n",
      "[[[26450.]\n",
      "  [30020.]\n",
      "  [28240.]\n",
      "  [29070.]\n",
      "  [28850.]\n",
      "  [29750.]\n",
      "  [31390.]\n",
      "  [29890.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "457.7517067144589\n",
      "[[[30020.]\n",
      "  [28240.]\n",
      "  [29070.]\n",
      "  [28850.]\n",
      "  [29750.]\n",
      "  [31390.]\n",
      "  [29890.]\n",
      "  [31090.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "397.7517088272532\n",
      "[[[28240.]\n",
      "  [29070.]\n",
      "  [28850.]\n",
      "  [29750.]\n",
      "  [31390.]\n",
      "  [29890.]\n",
      "  [31090.]\n",
      "  [30490.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "377.75171657452466\n",
      "[[[29070.]\n",
      "  [28850.]\n",
      "  [29750.]\n",
      "  [31390.]\n",
      "  [29890.]\n",
      "  [31090.]\n",
      "  [30490.]\n",
      "  [30290.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "389.7517038128249\n",
      "[[[28850.]\n",
      "  [29750.]\n",
      "  [31390.]\n",
      "  [29890.]\n",
      "  [31090.]\n",
      "  [30490.]\n",
      "  [30290.]\n",
      "  [30410.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "106.7517106859417\n",
      "[[[29750.]\n",
      "  [31390.]\n",
      "  [29890.]\n",
      "  [31090.]\n",
      "  [30490.]\n",
      "  [30290.]\n",
      "  [30410.]\n",
      "  [27580.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "20.751708914004226\n",
      "[[[31390.]\n",
      "  [29890.]\n",
      "  [31090.]\n",
      "  [30490.]\n",
      "  [30290.]\n",
      "  [30410.]\n",
      "  [27580.]\n",
      "  [26720.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "180.75170728792577\n",
      "[[[29890.]\n",
      "  [31090.]\n",
      "  [30490.]\n",
      "  [30290.]\n",
      "  [30410.]\n",
      "  [27580.]\n",
      "  [26720.]\n",
      "  [28320.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "569.7517003046152\n",
      "[[[31090.]\n",
      "  [30490.]\n",
      "  [30290.]\n",
      "  [30410.]\n",
      "  [27580.]\n",
      "  [26720.]\n",
      "  [28320.]\n",
      "  [32210.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "423.7517145983011\n",
      "[[[30490.]\n",
      "  [30290.]\n",
      "  [30410.]\n",
      "  [27580.]\n",
      "  [26720.]\n",
      "  [28320.]\n",
      "  [32210.]\n",
      "  [30750.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "436.75171722616045\n",
      "[[[30290.]\n",
      "  [30410.]\n",
      "  [27580.]\n",
      "  [26720.]\n",
      "  [28320.]\n",
      "  [32210.]\n",
      "  [30750.]\n",
      "  [30880.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "616.7516974034202\n",
      "[[[30410.]\n",
      "  [27580.]\n",
      "  [26720.]\n",
      "  [28320.]\n",
      "  [32210.]\n",
      "  [30750.]\n",
      "  [30880.]\n",
      "  [32680.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "153.7517085779049\n",
      "[[[27580.]\n",
      "  [26720.]\n",
      "  [28320.]\n",
      "  [32210.]\n",
      "  [30750.]\n",
      "  [30880.]\n",
      "  [32680.]\n",
      "  [28050.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "100.75171078727398\n",
      "[[[26720.]\n",
      "  [28320.]\n",
      "  [32210.]\n",
      "  [30750.]\n",
      "  [30880.]\n",
      "  [32680.]\n",
      "  [28050.]\n",
      "  [27520.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "458.7517029941142\n",
      "[[[28320.]\n",
      "  [32210.]\n",
      "  [30750.]\n",
      "  [30880.]\n",
      "  [32680.]\n",
      "  [28050.]\n",
      "  [27520.]\n",
      "  [31100.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "396.75171313429763\n",
      "[[[32210.]\n",
      "  [30750.]\n",
      "  [30880.]\n",
      "  [32680.]\n",
      "  [28050.]\n",
      "  [27520.]\n",
      "  [31100.]\n",
      "  [30480.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "403.75170278278705\n",
      "[[[30750.]\n",
      "  [30880.]\n",
      "  [32680.]\n",
      "  [28050.]\n",
      "  [27520.]\n",
      "  [31100.]\n",
      "  [30480.]\n",
      "  [30550.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "425.7517065438493\n",
      "[[[30880.]\n",
      "  [32680.]\n",
      "  [28050.]\n",
      "  [27520.]\n",
      "  [31100.]\n",
      "  [30480.]\n",
      "  [30550.]\n",
      "  [30770.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "620.7517116367864\n",
      "[[[32680.]\n",
      "  [28050.]\n",
      "  [27520.]\n",
      "  [31100.]\n",
      "  [30480.]\n",
      "  [30550.]\n",
      "  [30770.]\n",
      "  [32720.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "423.7517145983011\n",
      "[[[28050.]\n",
      "  [27520.]\n",
      "  [31100.]\n",
      "  [30480.]\n",
      "  [30550.]\n",
      "  [30770.]\n",
      "  [32720.]\n",
      "  [30750.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "281.75170529652524\n",
      "[[[27520.]\n",
      "  [31100.]\n",
      "  [30480.]\n",
      "  [30550.]\n",
      "  [30770.]\n",
      "  [32720.]\n",
      "  [30750.]\n",
      "  [29330.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "422.751700173991\n",
      "[[[31100.]\n",
      "  [30480.]\n",
      "  [30550.]\n",
      "  [30770.]\n",
      "  [32720.]\n",
      "  [30750.]\n",
      "  [29330.]\n",
      "  [30740.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "435.7517032382088\n",
      "[[[30480.]\n",
      "  [30550.]\n",
      "  [30770.]\n",
      "  [32720.]\n",
      "  [30750.]\n",
      "  [29330.]\n",
      "  [30740.]\n",
      "  [30870.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "531.7517042755951\n",
      "[[[30550.]\n",
      "  [30770.]\n",
      "  [32720.]\n",
      "  [30750.]\n",
      "  [29330.]\n",
      "  [30740.]\n",
      "  [30870.]\n",
      "  [31830.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "562.7517214544972\n",
      "[[[30770.]\n",
      "  [32720.]\n",
      "  [30750.]\n",
      "  [29330.]\n",
      "  [30740.]\n",
      "  [30870.]\n",
      "  [31830.]\n",
      "  [32140.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "485.75170483488785\n",
      "[[[32720.]\n",
      "  [30750.]\n",
      "  [29330.]\n",
      "  [30740.]\n",
      "  [30870.]\n",
      "  [31830.]\n",
      "  [32140.]\n",
      "  [31370.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "187.75170605083727\n",
      "[[[30750.]\n",
      "  [29330.]\n",
      "  [30740.]\n",
      "  [30870.]\n",
      "  [31830.]\n",
      "  [32140.]\n",
      "  [31370.]\n",
      "  [28390.]]]\n",
      "[[[2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.2483]\n",
      "  [2651.248 ]\n",
      "  [2651.248 ]]]\n",
      "534.7516947144721\n",
      "414.5422173916669\n"
     ]
    }
   ],
   "source": [
    "def lstm_model(x_train, y_train, x_test, y_test, model):\n",
    "    err = 0\n",
    "    result = []\n",
    "    for i,j in zip(x_test, y_test):\n",
    "        i = i.reshape(1, 8, 1)\n",
    "        print(i*10)\n",
    "        predict = model.predict(i)\n",
    "        print(predict)\n",
    "        predict = predict[0][0]\n",
    "        j = j[0]\n",
    "        err = (predict-j)**2\n",
    "        result.append(err)\n",
    "        print(math.sqrt(err))\n",
    "    return math.sqrt(sum(result)/len(result))\n",
    "print(lstm_model(x_train, y_train, x_test, y_test, regressor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'de'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-182-9385f25877d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msubmit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'20210323'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20210324'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20210325'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20210326'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20210327'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20210328'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'20210329'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredict_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'operating_reserve(MW)'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msubmit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-ac1e6d016992>\u001b[0m in \u001b[0;36mpredict_mean\u001b[0;34m(max_len)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mpredict_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mde\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredict_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program/Homework/competition_in_data_science/.venv/lib/python3.8/site-packages/numpy/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    212\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTester\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                 raise AttributeError(\"module {!r} has no attribute \"\n\u001b[0m\u001b[1;32m    215\u001b[0m                                      \"{!r}\".format(__name__, attr))\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'de'"
     ]
    }
   ],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['date'] = ['20210323', '20210324', '20210325', '20210326', '20210327', '20210328', '20210329']\n",
    "predict_list = predict_mean(4)\n",
    "submit['operating_reserve(MW)'] = predict_list\n",
    "submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(shape):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, kernel_initializer='normal', input_shape=(shape[1], shape[2]), activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(0,)\n",
      "(2594, 1, 7)\n",
      "(2594,)\n",
      "[[3087.  3183.  3214.  3137.  2839.  3186.  2960.7]]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "def create_week_data(past = 3):\n",
    "    # model = build()\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    x_test = []\n",
    "    y_test = []\n",
    "    for i in range(0, len(data)-7*past+7):\n",
    "        t = []\n",
    "        for j in range(past):\n",
    "            t.append(data.iloc[i+j*7][['備轉']])\n",
    "            try:\n",
    "                y = data['備轉'].iloc[i+j*7+7]\n",
    "            except:\n",
    "                y = None\n",
    "        if i >= 2586 and i <= 2613:\n",
    "            continue\n",
    "#         if i < 2600:\n",
    "#             x_train.append(t)\n",
    "#             y_train.append(y)\n",
    "#         else:\n",
    "#             x_test.append(t)\n",
    "#             y_test.append(y)\n",
    "        y_test.append(y)\n",
    "        x_test.append(x)\n",
    "\n",
    "    x_train = np.array(x_train)\n",
    "    y_train = np.array(y_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_test = np.array(y_test)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "x_train, y_train, x_test, y_test = create_week_data(3)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "print(x_test[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87, 3)\n"
     ]
    }
   ],
   "source": [
    "past = 3\n",
    "x_train, y_train, x_test, y_test = create_week_data(past)\n",
    "\n",
    "\n",
    "model = baseline_model(x_test.shape)\n",
    "x_train = x_train.reshape(-1, past)\n",
    "x_test = x_test.reshape(-1, past)\n",
    "print(x_test.shape)\n",
    "regr = MLPRegressor(random_state=1, max_iter=2000, hidden_layer_sizes=10).fit(x_train, y_train)\n",
    "\n",
    "# x_train, y_train, x_test, y_test = create_week_data(3)\n",
    "\n",
    "\n",
    "# model = baseline_model(x_test.shape)\n",
    "# x_train = x_train.reshape(-1, 3)\n",
    "# x_test = x_test.reshape(-1, 3)\n",
    "# print(x_test.shape)\n",
    "# regr = MLPRegressor(random_state=1, max_iter=1000, hidden_layer_sizes=10).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3087.  3183.  3214.  3137.  2839.  3186.  2960.7]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 7 features, but MLPRegressor is expecting 3 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-486-27ab28808409>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3087\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3183\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3214\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3137\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2839\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3186\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2960.7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program/Homework/competition_in_data_science/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1407\u001b[0m         \"\"\"\n\u001b[1;32m   1408\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program/Homework/competition_in_data_science/.venv/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mdecision\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;31m# Initialize first layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program/Homework/competition_in_data_science/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ensure_2d'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/program/Homework/competition_in_data_science/.venv/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    366\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m                 f\"is expecting {self.n_features_in_} features as input.\")\n",
      "\u001b[0;31mValueError\u001b[0m: X has 7 features, but MLPRegressor is expecting 3 features as input."
     ]
    }
   ],
   "source": [
    "predict = []\n",
    "for i in range(7):\n",
    "    x = np.array([3087,3183, 3214, 3137, 2839, 3186, 2960.7]).reshape(-1, 7)\n",
    "    print(x)\n",
    "    print(regr.predict(x))\n",
    "    predict.append(regr.predict(x)[0])\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191.4234236396863\n"
     ]
    }
   ],
   "source": [
    "# predict = [3168, 3154, 3176, 3275, 2906, 2957, 3136]\n",
    "# result = [316,321,322,316,301,279,314]\n",
    "# result = [i*10 for i in result]\n",
    "result = [2933, 3074, 3087, 3183, 3214, 3137, 2839]\n",
    "err = 0\n",
    "for i in range(7):\n",
    "    err += (result[i]-predict[i])**2\n",
    "print(math.sqrt(err/7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit1d440c7be74e450ba66fd8acf4425a08"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
